# AWS-DeepRacer
![AWS_Deepracer_Model (1)](https://github.com/user-attachments/assets/0c5373d7-772e-4269-99dd-7b06e4451a20)

Video: https://youtu.be/f-EN8WQZyWA

## Overview

AWS DeepRacer is a platform created by Amazon Web Services (AWS) that helps users learn reinforcement learning (RL) through an exciting and hands-on approach. It features a 1/18th scale autonomous car that can be trained to navigate a track using RL models. Users develop and refine their models in a virtual racing simulator before testing them on the physical car.The platform also includes the AWS DeepRacer League, where participants compete globally, making learning fun and competitive. It‚Äôs designed to be accessible for beginners and offers tutorials and resources, providing a practical way to explore machine learning concepts.

## My AWS DeepRacer-Powered Experience

I had the exciting opportunity to compete in the AWS DeepRacer League for Bulgaria, where I achieved 6th place with a personal best time of 8.703 seconds. This competition challenged me to train and optimize a reinforcement learning model for autonomous racing, pushing me to refine my skills in machine learning and model tuning. The experience was both fun and insightful, giving me the chance to connect with like-minded individuals and dive deeper into the world of AI and autonomous systems. Competing locally and seeing my efforts pay off was a truly rewarding experience!

![aws car](https://github.com/user-attachments/assets/3e25fbb4-982c-43ab-99b6-9bf1358fe4c3)

## From Model to Track

### üß† Step 1:

The first step was familiarizing myself with AWS DeepRacer's environment and understanding the basics of reinforcement learning. I explored the AWS DeepRacer console, set up my virtual environment, and began learning how to create and train models. This foundational step was essential in understanding how to apply machine learning algorithms to autonomous driving tasks. I also spent time reviewing the rules of the competition, ensuring I was well-prepared to tackle the challenge ahead.

### üíª Step 2: Setting Up the Model and Environment

In this step, I focused on configuring the AWS DeepRacer environment and setting up the simulation model. I worked with the AWS DeepRacer console to create and customize my racing model, selecting the appropriate settings for the track and car. This phase involved understanding the reinforcement learning algorithms and ensuring that my model was ready to learn from the simulated racing environment.


### üîß Step 3: Training and Fine-Tuning the Model
Once everything was set up, it was time to train my model. 
I watched as my car began to navigate the track, learning through trial and error. Each time it made a mistake, the system would reward or penalize it based on the actions taken. Fine-tuning the model became a key part of this process. I adjusted the [reward function](https://github.com/Nevtimova/AWS-DeepRacer/blob/main/aws%20deepracer-%20code.txt) to improve its performance, gradually increasing its ability to make faster and more accurate decisions. It was exciting to see my model improve over time, but also challenging‚Äîtuning reinforcement learning models often requires a balance of patience and persistence. I spent several iterations testing different strategies and adjusting settings until I felt the model was performing well.

### üèéÔ∏è Step 4: Testing and Optimizing for Performance
With the model trained, it was time to test its performance. I ran several simulations, analyzing the car‚Äôs ability to stay on track and complete laps efficiently. Every test brought new insights, revealing areas where the car‚Äôs performance could be improved. I made adjustments, testing different variations of the model to optimize speed, accuracy, and handling. The key was not just completing the race, but doing so in the shortest time possible while maintaining control. After several rounds of testing, I felt confident that my model was ready for the real challenge.

### üèÅ Step 5: Competing and Achieving Results
Finally, the moment arrived: the competition. I entered the AWS DeepRacer League, eager to see how my model would fare against other participants. The atmosphere was electric as cars raced on the track, and I couldn‚Äôt wait to see how mine would perform in real-time. While I didn‚Äôt win the top prize, the experience was incredibly rewarding. I had learned so much about reinforcement learning, autonomous driving, and the power of iteration. The competition gave me a deeper appreciation for the complexities of RL and motivated me to continue refining my models. It was a huge milestone in my learning journey, and I knew it was just the beginning.
